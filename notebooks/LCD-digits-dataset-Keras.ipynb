{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCD digits dataset shows NMF parts-based decomposition\n",
    "\n",
    "This synthetic image dataset shows very nicely how NMF decompose images as the sums of their parts.  The collection of images is encoded as a 2d array of non-negative values.  Each row corresponds to an image, and each column corresponds to a pixel.  The non-negative entries represent the whiteness of the pixel, encoded here as a value between 0 and 1.\n",
    " \n",
    " * See also the accompanying blog post http://building-babylon.net/2016/12/28/an-lcd-digit-dataset-for-illustrating-the-parts-based-representation-of-nmf/ .\n",
    " * Original found https://gist.github.com/benjaminwilson/b25a321f292f98d74269b83d4ed2b9a8#file-lcd-digits-dataset-nmf-ipynb\n",
    "\n",
    "Released under Apache Licence v2.0.  I hope you find it useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length = 4  # length of any LCD cell (\"stroke\")\n",
    "shape = (2 * length + 5, length + 4)  # shape of the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for displaying a vector as an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def show_as_image(vector):\n",
    "    \"\"\"\n",
    "    Given a 1d vector representing an image, display that image in \n",
    "    black and white.  If there are negative values, then use red for \n",
    "    that pixel.\n",
    "    (displaying negative pixel values in red allows e.g. visual contrasting\n",
    "    of PCA and NMF components)\n",
    "    \"\"\"\n",
    "    bitmap = vector.copy().reshape(shape)  # make a square array\n",
    "    bitmap /= np.abs(vector).max()  # normalise (a copy!)\n",
    "    bitmap = bitmap[:,:,np.newaxis]\n",
    "    rgb_layers = [np.abs(bitmap)] + [bitmap.clip(0)] * 2\n",
    "    rgb_bitmap = np.concatenate(rgb_layers, axis=-1)\n",
    "    plt.figure(figsize=(2, 1))\n",
    "    plt.imshow(rgb_bitmap, interpolation='nearest')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for generating the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vertical_stroke(rightness, downness):\n",
    "    \"\"\"\n",
    "    Return a 2d numpy array representing an image with a single vertical stroke in it.\n",
    "    `rightness` and `downness` are values from [0, 1] and define the position of the vertical stroke.\n",
    "    \"\"\"\n",
    "    i = (downness * (length + 1)) + 2\n",
    "    j = rightness * (length + 1) + 1\n",
    "    x = np.zeros(shape=shape, dtype=np.float64)\n",
    "    for delta in range(length):\n",
    "        x[i + delta, j] = 1.\n",
    "    return x\n",
    "\n",
    "def horizontal_stroke(downness):\n",
    "    \"\"\"\n",
    "    Analogue to vertical_stroke, but it returns horizontal strokes.\n",
    "    `downness` is here a value in [0, 1, 2].\n",
    "    \"\"\"\n",
    "    i = (downness * (length + 1)) + 1\n",
    "    x = np.zeros(shape=shape, dtype=np.float64)\n",
    "    for j in range(length):\n",
    "        x[i, 2 + j] = 1.\n",
    "    return x\n",
    "\n",
    "print(horizontal_stroke(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "strokes = [horizontal_stroke(k) for k in range(3)] + [vertical_stroke(k, l) for k in range(2) for l in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def random_composition():\n",
    "    \"\"\"\n",
    "    Return a random composition of 2, 3, 4, or 5 strokes as a single 2d numpy array.\n",
    "    (So not guaranteed to look like a real digit!)\n",
    "    \"\"\"\n",
    "    x = np.zeros(shape=shape, dtype=np.float64)\n",
    "    num_strokes = random.choice([2, 3, 4, 5])\n",
    "    sample = random.sample(strokes, num_strokes) # without replacement\n",
    "    for atom in sample:\n",
    "        x += atom\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1.  1.  1.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "bitmap = random_composition()\n",
    "print(bitmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEMAAABhCAYAAACNrhxOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAAYRJREFUeJzt3LFNw1AUQNH3EEWUlgVcUiJaBmAI5ssQGQBmoMwC9HSf\nIhS3sfXQtx1b3NOksGU9X33Zshw5W2uhq7tbD7AlxgBjgDHAGGAMMAaUYmTmMTOfM/O49EBLqM5/\nXzzeU0S8R8RbZn52T7e+x4g4RcRLRHyM7VSNMfz+nvpmurkhJmJUrxmXOSbZgMvUxmqM7/45NmHy\nPLybQPWa8WdrPA1n5qzHc2WAMcAYYAwwBnTfTcbuGnNf6dfgygBjgDHAGGAMMAYYA4wBxgBjgDHA\nGGAMMAYYA4wBxgBjgDHAGGAMMAYYA7rfm+zx/cgYVwYYA4wBxgBjgDHAGGAMMAYYA4wBxgBjgDHA\nGGAMMAYYA4wBxgBjgDHAGGAMMAYYA4wBxgBjgDHADwOAKwOMAcYAY4AxYLG7yR7/+ObKAGOAMcAY\nUI1xWHSK9UyeRzXG0D/HJgxTG7PyQJWZDxHxGtcPBe7xO3+HuIY4t9a+xnYqxfgvvICCMcAYYAww\nBhgDjAE/MEkkDfXkI60AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10708e7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_as_image(bitmap.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 104)\n"
     ]
    }
   ],
   "source": [
    "N = 200\n",
    "samples = [random_composition().flatten() for _ in range(N)]\n",
    "X = np.vstack(samples)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Learning the individual cells with a Keras based NNMF\n",
    "\n",
    "Based on formula (1) from http://www.cs.princeton.edu/courses/archive/spring12/cos424/pdf/lee-seung.pdf, an image $i$ from our dataset $X$ is approximated by a weighted combination $\\mathbf{W}_i$ of $k=1, \\cdots, K$ basis images $\\mathbf{H}_k$.\n",
    "\n",
    "$$ \\mathbf{X}_i \\approx \\mathbf{W}_i \\mathbf{H} = \\sum_{k=1}^K \\mathbf{W}_{ik} \\mathbf{H}_{k}$$\n",
    "\n",
    "We can express this formula into a two layers neural network:\n",
    "\n",
    " 1. Given an image id $i$, find its coordinates $\\mathbf{W}_i$ in terms of basis images \n",
    "\n",
    "$\\Rightarrow$ our input will be a simple vector of row indexes `X_image_ids` and `keras.layers.Embedding` will mapped each id $i$ into its embedding $\\mathbf{W}_i$\n",
    "\n",
    " 2. (1bis) Reshape the embedding into `Reshape((embedding_size,))`\n",
    "\n",
    " 2. Given a set coordinates/weights $\\mathbf{W}_i$, multiply with $\\mathbf{H}$ to reconstruct the image \n",
    "\n",
    "$\\Rightarrow$ this simply translates as a `keras.layers.Dense` layer with `output_dim` equals to the number of pixels and no biases \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12.0-rc0\n",
      "1.1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.layers import Embedding, Reshape, Dense, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.constraints import nonneg\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "K.set_session(sess)\n",
    "\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n",
    "\n",
    "\n",
    "n_images, n_pixels = X.shape\n",
    "K = embedding_size = 7\n",
    "\n",
    "X_image_ids = np.arange(n_images)\n",
    "\n",
    "X_image_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### EXERCISE \n",
    "# initialise a \n",
    "# model = Sequential(...)\n",
    "# with all the 3 layers listed above\n",
    "# You can test it by doing \n",
    "# show_as_image(X[1])\n",
    "# show_as_image(model.predict(np.array([[0]])))\n",
    "# which should show some random prediction as the model is not trained yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### SOLUTION ###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "weights_contraint = None\n",
    "image_to_embeddings = Embedding(input_dim=n_images, output_dim=embedding_size, input_length=1, init='uniform', W_constraint=weights_contraint)\n",
    "\n",
    "embeddings_to_images = Dense(output_dim=n_pixels, bias=False, W_constraint=weights_contraint)\n",
    "\n",
    "model = Sequential([\n",
    "    image_to_embeddings,\n",
    "    Reshape((embedding_size,)), # getting rid of the superfluous dimension of input_length=1\n",
    "    embeddings_to_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEMAAABhCAYAAACNrhxOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAAYNJREFUeJzt3L1Nw1AUQOF7EUWUlgVcpkS0DMAQzJchGABmSJkF6Oke\nhSlOga0b/BNHnK9JEcu5PnqyFdlyttZCvbtrD7AlxgBjgDHAGGAMMAaUYmTmPjOfMnO/9EBLqM5/\nX9zfY0S8R8RrZp4mT7e+Q0QcI+I5Ij6GNqrG6H4+j9NmurouRmJUzxnnOSbZgPPYl9UYX9Pn2ITR\n4/BqAtVzxsXW+DecmbPuz5UBxgBjgDHAGLDY1WTuM/1vhq5Yf/1tVwYYA4wBxgBjgDHAGGAMMAYY\nA4wBxgBjgDHAGGAMMAYYA4wBxgBjgDHAGOBdeHBlgDHAGGAMMAYYA276kYS5uTLAGGAMMAYYA4wB\nxgBjgDHAGGAMMAYYA4wBxgBjgDHAGGAMMAYYA4wBxgAfSQBXBhgDjAHGAGOAd+HBlQHGAGOAMaAa\nY7foFOsZPY5qjG76HJvQjX2ZlT9UmfkQES/RvyjwFt/zt4s+xFtr7XNoo1KM/8ITKBgDjAHGAGOA\nMcAY8A0F1ycScZZ0KgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ade4320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEMAAABhCAYAAACNrhxOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAABElJREFUeJztnF1IFWkYx/+v1fHYGkZ5diO6OASpYUV+wFqGsFddZEKB\nbBRLIKwQxV4sBHkRHIraLMFdCJYKuktoAwXZiEAMsbqQVu80tjoUoaKwdiCNlI3Ziyl6ZnyeszP0\nye7/Bwfn/c/7Mf54Oe+ZM3PGeZ4H4lPwqQ/gc4IyBJQhoAwBZQgoQ0AZgkgynHPLnXPVzrnlH/qA\nPgRRj39pxP62ArgD4IBz7v47H93HpwLAFQD1AO5alaLKSL/+e+XdjumTk8Z7kPEYAFKpFBKJRGBH\ne3u72qC/v1/NV12+rOYdeQbPZDJq/sjIb4TKfwPI+ZuP8wwTWcZLAEgkEigsLAzsqKioUBuMjo6q\n+VfGAM45c/B0Oq3ms0b9hJHj9f9hwdVEEHVm+IyPL4paW1vVqiPDw2reuHu3mne3tJjDlpWV6W2M\n+sdC5acAzpm9v4UzQ0AZAsoQUIaAMgSxVpOv9+5FaWlpIHty8aJad8lSvev5+Xk1/2XPHnPcMSM/\nfv68mnceORIc0+w5CGeGgDIElCGgDAFlCGKtJr29vYvOLk+f0z/1Pzt6VM1TqZSab8sz7kMj7+7W\nz05OX70aKGezWbS1teUZwYczQ0AZAsoQUIaAMgQuyv0ZzrlqAH/sA/BlaN+E0Ub/ngv41si9Y+Hv\np95y9swZNV+zdq2aj08Ej2oYQI2/WeN5nnVonBkSyhBQhoAyBJQhiHVu8huA8HWv7426Pxr5BSNv\neP7cHPfQ4cNq3tXVpeaZUHnS7DkIZ4aAMgSUIaAMAWUIYp2bfANgZWjfdH292mZmZkbNJyf19/ai\noiJz/C6jzcqRETU/UVUVKOcA3PI3eW4SFcoQUIaAMgSUIaAMQaylVdtn3WH6k3EjW0lJiZpbF5cA\n4Glnp5pvMur/XlsbKM/NzWFsbAzg0hodyhBQhoAyBJQhiLWarAcQPp0q2b5dbTM0NKTmDQ0Naj4w\nMGCOv+vVKzV/YNRvDpUnAVzyN7maRIUyBJQhoAwBZQhiXUSaSCZRUBD0993mzWrdpqYmNb9u3HpQ\nq6Y+GeOHPH9WV6t5+AZu+/JUEM4MAWUIKENAGQLKEMRaTYqLixf94vmLC/pNBj1GH8t27FDzLRs3\nmuP29fWp+Smj/op16wLlhYUFYHra7P8NnBkCyhBQhoAyBJQhiLWadHR0oLy8PJD9uk3/2cxJo49D\nt2+recbIAeDnxkY1v/dA/66rZsOGQFn/nmwxnBkCyhBQhoAyBJQhiHXdpApAcWjfD9euqW2am8NX\nL3wOGmM8NG6UA4C6ujo17+nRz4AqKysD5Vwuh8HBQYDXTaJDGQLKEFCGIOrH8SQAvFB2ZLPZWAP+\nZeSzs9bz2ICpqSk1t57SksvlrL6TeQ/O87x/fQHYD8D7D7z25/s/oy6tqwHshP+gwLzPx/tMScJ/\n4uNNz/OsyRlNxv8FvoEKKENAGQLKEFCGgDIElCH4BwqJUfH4CUvQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11aead358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_as_image(X[1])\n",
    "show_as_image(model.predict(np.array([[0]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### EXERCISE \n",
    "# compile the model using mean_squared_error and Adam optimizer\n",
    "# then fit the model by feeding X_images and X as x/y\n",
    "# use fit(..., batch_size=n_images, verbose=0, nb_epoch=1000)\n",
    "\n",
    "# Check your result by looking at the predicted image as above\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11aef2a20>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### SOLUTION\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam())\n",
    "\n",
    "X_image_ids = np.arange(n_images)\n",
    "\n",
    "model.fit(\n",
    "    x=X_image_ids, \n",
    "    y=X,\n",
    "    batch_size=n_images, verbose=0, nb_epoch=1000)\n",
    "          \n",
    "#repeats = 1000\n",
    "#model.fit(x=np.tile(X_image_ids, repeats), y=np.tile(X, (repeats, 1)),\n",
    "#          batch_size=n_images, verbose=2, nb_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEMAAABhCAYAAACNrhxOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAAYRJREFUeJzt3LFNw1AUQNH3EEWUlgVcUiJaBmAI5ssQDAAzUGYBerpP\nYYpbEOsF+zuOuKdJYct5vvqyZVlyttZCo5tLD7AlxgBjgDHAGGAMMAaUYmTmPjMfM3Pfe6AeqvPf\nFo/3EBFvEfGSmR+zp1vffUQcIuIpIt5P7VSNMfz8HubNdHFDTMSoXjOOS0yyAcepjdUYX/Pn2ITJ\n8/BuAtVrxtnWeBrOzEWP58oAY4AxwBhgDOh2N1n6Sv+bU3esv/63KwOMAcYAY4AxwBhgDDAGGAOM\nAcYAY4AxwBhgDDAGGAOMAcYAY4AxwBhgDOj23mQNvoXvyBhgDDAGGAOMAcYAY4AxwBhgDDAGGAOM\nAcYAY4AxwBhgDDAGGAOMAcYAY4AxwBhgDDAGGAOMAX4YAFwZYAwwBhgDjAFX/WGApbkywBhgDDAG\nVGPsuk6xnsnzqMYY5s+xCcPUxqw8UGXmXUQ8x/ihwGv8zt8uxhCvrbXPUzuVYvwXXkDBGGAMMAYY\nA4wBxoBvrHMkEF25sM8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b02c940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEMAAABhCAYAAACNrhxOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAAkxJREFUeJzt3EFOIkEUh/H3RhzFBBhDQsKOpUvjdg4wh5jzeYg5gJ5h\nlu5YGWJYACq0C1z8F/3a6q5uYDLfb2NSYFt+qXQFusGLojDsfTv2BE4JMQQxBDEEMQQxBDFEUgx3\nv3L3O3e/6npCXUidfy/xeLdm9mBmv939b/bsDu/GzO7N7KeZPUZPSo0x+/x5nzeno5tZRYzUc8ZT\nGzM5AU9VD6bGWOfP4yRU/h/sJiL1nFHbcrksHXf30vHdbhceK3plPRqN6k+sAitDEEMQQxBDEENk\n7ybnwfhgMMg99JeiXSbasb7CyhDEEMQQxBDEENm7yTGvx61Wq1aPx8oQxBDEEMQQxBDZu8m2jVk0\n1Ou1+0YdK0MQQxBDEEMQQ2Sfjs+C8ffcAydYr9u90MfKEMQQxBDEEMQQ2btJtGt8D8bfgvEf19fh\n33hZLErHh8Nh+DtNsDIEMQQxBDEEMQQxRPbWGl3+f635ca9FsH1WiV4kNn0rkpUhiCGIIYghiCHy\nb0k44oeEPbqI9N7sTUdWhiCGIIYghiCGyL+IdFb+CmG77f5mhV3DXSPCyhDEEMQQxBDEEPm7SbBr\nHOLGt/OLi9LxzWbT6HisDEEMQQxBDEEMkb2bvAbj8/m8dHw8Htd6vpnZZDIpHe/3+5Vzq4uVIYgh\niCGIIYghOvuamel02tWhO8PKEMQQxBDEEKkxLjudxeFU/h+pMWb58zgJs6oHPeWWAncfm9kv239R\n4L/4PX+Xtg/xpyiK5+hJSTH+F5xABTEEMQQxBDEEMQQxxAd0klQ2lEqUVgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b07af28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_as_image(X[0])\n",
    "show_as_image(model.predict(np.array([[0]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising the basis of images learnt\n",
    "\n",
    " * A vanilla neural net will converge to a basis of images with good predictive power but not meaningful  \n",
    " * Go back to the `model` above and use `keras.constraints.nonneg` (look at doc) to add positive constraints on the layers and look at the learnt basis (each basis image should be one of the 7 cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEMAAABhCAYAAACNrhxOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAAjpJREFUeJzt3DFOAkEYhuH/F0KMJV6A0oTGYMkBvIKJ16DiANTcwXAI\nD4CddiSWXkBDaRAYCyy+gllmmQWW+D4JMZklw/Bmshthg4cQDBsXp15AnRBDEEMQQxBDEEMQQyTF\ncPcrd++5+9WhF3QIqetvJs53a2ZTM3t09/fs1R3fjZlNzKxvZi+xJ6XG6Pz9neSt6eQ6VhAj9Zzx\nUcVKauCj6GBqjO/8ddRC4fvgaiJSzxmlPUTGY/V/Cua6jIw/pS8nCTtDEEMQQxBDEENkX02m0+nW\n8X6/nzv1TsPhcOv4aDTaaz52hiCGIIYghiCGyL6anPIbudVqVel87AxBDEEMQQxBDJF9NXH3Ktax\nl2az2g/q2BmCGIIYghiCGCL7dLxer6tYRy1em50hiCGIIYghiCE85ZMqd++Z2WuZibvdbqmFtFqt\n6LHFYrF1fDablXoNM7sLIbzFDrIzBDEEMQQxBDEEMUT2P2qxL3IajUbu1Du1I+Nfe87HzhDEEMQQ\nxBDEEAe7XfoYqr4Zgp0hiCGIIYghiCGyrybz+byKdeyl6psh2BmCGIIYghiCGCL7atJuxz5vOj/s\nDEEMQQxBDEEMcbDbpcfjcannF90asVwut44PBoMdqyuHnSGIIYghiCGIoUIIOx9m1rPN1xTn/ugV\nvU92hiCGIIYghkiNEfuprHNT+D5SY3Ty11ELnaKDqfeOX5vZvW1+KPAcf+fv0jYhnkMIn7EnJcX4\nLziBCmIIYghiCGIIYghiiF+yk68Oy36qmAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11aed87b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEMAAABhCAYAAACNrhxOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAAkdJREFUeJzt3D9uGkEYhvHvgxAsSnKBLVNGpEKpqHIIXyESZ0HKFXwG\nlIoq7uw65V4gHVJCAZMCF28xs57dWf7Fz09ClgY0Hh6NGLHYeAjBcDS49AKuCTEEMQQxBDEEMQQx\nRFYMd5+4+8zdJ6de0Cnkrv9d5nyfzOynmd27+6/i1Z3fRzN7MLMvZvaYelBujOrl50PZmi6usoYY\nua8ZdR8ruQJ10525Mf6Wr+MqND4PThOR+5rR2n6/bzU+Go2Scx0Oh+j4cDhsv7AG7AxBDEEMQQxB\nDFF8mlRVFR3v+5U+ZjweR8d3u12n+dgZghiCGIIYghii+DS55CdyXU+NFHaGIIYghiCGIIYoPk0G\ng8v1TP3m+HWx7vO9ScQQxBDEEMQQN/3eJPVJS9d3LOwMQQxBDEEMQQxRfJrUdR0dXywW0fHUe5mm\nT+FTV7Q2m03z4lpiZwhiCGIIYghiCGKI4qN1uVxGx1erVenUr/qWGP/ecT52hiCGIIYghiCGuOnL\nfn3/dT87QxBDEEMQQxBDFJ8m7t7HOjp53/N87AxBDEEMQQxBDFF8mqT+zfIc/vQ8HztDEEMQQxBD\nEEN4zpUqd5+Z2VObidfrdXR8Op1Gx7fbbXKuyST+7TDz+bzNkszMPocQnlN3sjMEMQQxBDEEMVQI\n4dWbmc3MLPwHt1nT82RnCGIIYghiiNwYdyddxfk0Po/cGFX5Oq5C1XRn7hu1D2b21Y5fFHiL3/N3\nZ8cQP0IIv1MPyorxVvACKoghiCGIIYghiCGIIf4Bbjq1725HfwEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b55c9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEMAAABhCAYAAACNrhxOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAAkdJREFUeJzt3K9yWkEYhvHvg8BkYmOQ4Co7qewF1FRjYnMZkdxKDLqm\nF9C6VFdmUJgqDP+3gnbmFWdPlrNnyen0+ZnMLMxmebLDDuSAhxAMJ723XkCXEEMQQxBDEEMQQxBD\nJMVw9xt3v3P3m9ILKiF1/VeJ8703s29mdu/uP7NXd3nvzOzJzD6a2ffYnVJjjP/8fMpb05sbW02M\n1OeMlzZW0gEvdTemxljnr6MTah8Hp4lIfc4423K5rBzfbDaV471e/O+y3+8rxyeTyfkLq8HOEMQQ\nxBDEEMQQ2afJYrGoHB+NRrlTv2o6nVaOz+fzRvOxMwQxBDEEMQQxRPZpcjwe21hHI4PBoNX52BmC\nGIIYghiCGCL7NOn3+22soxO/m50hiCGIIYghiCGyT5PVatXGOhpZr9v9Rx87QxBDEEMQQxBDeMq1\n4+5+Z2bP50z8JTJ+iIzXnUmxM+MhfTl/fQgh/IjdyM4QxBDEEMQQxBDEENkv1GazWeX458fH3Klf\ntd1uK8eHw2Gj+dgZghiCGIIYghgi+zSJXcp8CbHTpCl2hiCGIIYghiCGyD5NDofYG3nlcYFbQcQQ\nxBDEEMQQ2adJ28/o52j6jlYMO0MQQxBDEEMQQxS7JCF2yrh75fix5l2r2Md7Gnzsh0sSUhFDEEMQ\nQxBDFPuamd1uV2rqYtgZghiCGIIYIjXGddFVXE7t40iNMc5fRyeM625MfaF2a2af7PRFgf/i9/xd\n2ynE1xDCr9idkmL8L3gCFcQQxBDEEMQQxBDEEL8BwXBdnd7dCqUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b59c400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEMAAABhCAYAAACNrhxOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAAkFJREFUeJzt3L1qG0EUhuFzjH6MiavUwipTBrtwEVDraxABVbosVRK+\nCF9AAimSOpDGRo2btMESgnEhB77Aznq0MyvJ5H0aw8gcj14GLWvL8hCCYevk0Bs4JsQQxBDEEMQQ\nxBDEEEkx3P3M3S/d/aztDbUhdf+dxHkfzeyLmX1295/Zu9u/D2Z2a2afzOxr7JtSYwxfvt7m7eng\nhlYTI/U1477ETo7Afd2DqTGe8vdxFGqfB1cTkfqasbPxeFxsVqdTvc3FYlHsZ5hxMv5BDEEMQQxB\nDJF9NZnNZpXr0+k0d/SrriPr3xrO42QIYghiCGIIYojW7k32ofStNCdDEEMQQxBDEENkX002m02J\nfTRyWngeJ0MQQxBDEEMQQ2RfTbrdbol9NPKn8DxOhiCGIIYghiCG8JT3jrv7pZl932VwbO56va5c\nXy6X0VmDwaByvd/v77IlM7OrEMKP2IOcDEEMQQxBDEEMQQyRfaM2Go0q1909d/Sr5vN55fpkMmk0\nj5MhiCGIIYghiCGyryb7uGrErFarovM4GYIYghiCGIIYIvtqEvvHmH3o9XpF53EyBDEEMQQxBDFE\n9qXgkB9gFPuDVFOcDEEMQQxBDEEM0dpbEi4i6+8i679rZp1H1n+lb+cv3pKQihiCGIIYghiitV9T\nPRSc9VhwVh1OhiCGIIYghkiNUfofBQ+l9nmkxhjm7+MoDOseTL1Re29mN7b9oMC3+Dl/p7YNcRdC\niN4TJsX4X/ACKoghiCGIIYghiCGIIZ4BD0lQf789SqoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b5f0898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEMAAABhCAYAAACNrhxOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAAilJREFUeJzt3LFuUzEYQOHfhYSoDAzAxJKREZVsPAASCxMTz9eJiQWp\nDwBTYIWxO2JjgCVmCEhnqF3n+t7mVpxvqeSkjnNqxWrS3pRzDu2dHHsBc2IMMAYYA4wBxgBjQFOM\nlNJpSukspXQ69YKm0Lr+u43zPYuIjxHxNqX0rXt1N+9pRJxHxIuI+FS6U2uM9d+v531rOrp1VGK0\nvmZcjrGSGbis3dga41f/Omah+jw8TaD1NeNg9wrjpfq1H1k6ufq7drvdIUu6ljsDjAHGAGOAMaD7\nNHlVGP/QOzHkwqnxunD/9wMfx50BxgBjgDHAGNB9mqQxVjGTx3ZngDHAGGAMMAZ0nyald7Ruwp2R\n53NngDHAGGAMMAZ0nybH/Kjt58jzuTPAGGAMMAYYA7pPk9LnI5vC+LIwXvtjq9+F8YvK9wzhzgBj\ngDHAGGAMMAZ0H62bzdWH6Ha77Z36Wu8K428GzufOAGOAMcAYYAzoPk1Wq9UY6xhk7H9PdmeAMcAY\nYAwwBnSfJstl6Y2828edAcYAY4AxwBjQfZosFosx1jHI/ZHnc2eAMcAYYAwwBqSWy9mllM4i4vMh\nE38vjD8qjH+tzPWkMP6gfTn/PM85fynd6M4AY4AxwBhgDJjsMjOPp5p4Qu4MMAYYA4wBrTGO9+ny\nuKrPozXGun8ds7Cu3dj6i9rDiHgZ+wsF3sbr/K1iH+Ii5/yjdKemGP8LX0DBGGAMMAYYA4wBxoA/\ngDQ4BhbTo+UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b6400b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEMAAABhCAYAAACNrhxOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAAjFJREFUeJzt3LGOEkEcgPH/gMTLtXYWhtLSnOV1Nj6Eb8AjkJCQ8Aa8\nwz2EjYXJ2Wl95cXCzt5IZC2w+IqddWB2YY3fr7lkgGX4brKTBUJqmiZ0MLn0BMbEGGAMMAYYA4wB\nxoCiGCml65TSTUrpeugJDaF0/k8Kj/cqIu4j4l1K6aF6duf3MiLuIuI2Ij7l7lQaY/7n713dnC5u\nHh0xSs8Zj33MZAQeu24sjfGjfh6j0Pk63E2g9JxxtMVi0TqeUjr6WNPptHV8u90efawurgwwBhgD\njAHGgOrdZLVatY5vNpvaQ//VbrdrHZ/NZicdz5UBxgBjgDHAGFC9m5xyrdGXvj8NdGWAMcAYYAww\nBlTvJpf8fsdk0u//0pUBxgBjgDHAGFC9m+Q+0ziHvp/blQHGAGOAMcAYUL2brNfr1vHlctk6nruW\n2e/3Rz933++yuTLAGGAMMAYYA4wBqeRtu5TSTUR8brvtTeYxHyomVepFZvxr/iGvm6b5krvRlQHG\nAGOAMcAYUH2hdslv2P/q+XiuDDAGGAOMAcaA6t2k7zP6Mfr++MqVAcYAY4AxwBhQvZs87WMWI+HK\nAGOAMcAYYAyo3k0+ZsafZ8Zz1xM/O54j95iOz0dO4soAY4AxwBhgDBjsZ2a+DXXgAbkywBhgDDAG\nlMa4GnQW59P5OkpjzOvnMQrzrhtLv+D2LCLexuGHAv/F3/m7ikOI903TfM/dqSjG/8ITKBgDjAHG\nAGOAMcAY8Bth2UOsVJWzWAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b61e240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEMAAABhCAYAAACNrhxOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAAiJJREFUeJzt3LFuUzEYQOHfCETJAhIMjFmQYKu68gDMGTLxEKyMHXiV\nzpl5AHgGJJaOSKUSsAQU0GUIwxlq41z7JkGcb6nkpI57al2ranLTMAyhrVuHXsAxMQYYA4wBxgBj\ngDGgKkZKaZZSOkspzaZe0BRq13+7cr7TiHgXES9TSh+aV7d/TyPiIiKeR8T73JNqY8z/fL1oW9PB\nzaMQo/aacdljJUfgsvRgbYzv7es4CsWfw9MEaq8ZO3u14wuWfit3M+Nv6pdTxZ0BxgBjgDHAGNB8\nmqxWqxvHF4tF69R/9TEz/mTkfO4MMAYYA4wBxoDm02Sz2fRYxyg/O8/nzgBjgDHAGGAMaD5NZrPD\n/SvlV+f53BlgDDAGGAOMAc2nyXq97rGOUR51ns+dAcYAY4AxwBjQfJosl8sbx19nnv8jM/6t8Bp3\nMuOPC98zhjsDjAHGAGOAMcAY0Hy0fs2M32+duMKXzPiDkfO5M8AYYAwwBhgDmk+T3B9R++BbEiZk\nDDAGGAOMAc2nyb0eqxip9yeH3BlgDDAGGAOMAc0X5N5vMtvFVef53BlgDDAGGAOMAc2nSW6C88z4\np8z4s8JrfM6Mj/3IZo47A4wBxgBjgDFgstvMnE818YTcGWAMMAYYA2pjnEy6iv0p/hy1Mebt6zgK\n89KDqea+4ymlhxHxIrY3CvwX7/N3EtsQb4dhuM49qSrG/8ILKBgDjAHGAGOAMcAY8BtG4jOxwQ2K\nPgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ae7ea90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for component in embeddings_to_images.weights[0].eval():\n",
    "    show_as_image(component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
