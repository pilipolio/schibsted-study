{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next artist prediction in radio playlists Ã  la Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12.0-rc0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading and loading playlists and songs metadata\n",
    "\n",
    "See http://www.cs.cornell.edu/~shuochen/lme/data_page.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2017-01-24 12:20:11--  http://www.cs.cornell.edu/~shuochen/lme/dataset.tar.gz\n",
      "Resolving www.cs.cornell.edu... 132.236.207.20\n",
      "Connecting to www.cs.cornell.edu|132.236.207.20|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 15344424 (15M) [application/x-gzip]\n",
      "Saving to: 'dataset.tar.gz.7'\n",
      "\n",
      "dataset.tar.gz.7    100%[=====================>]  14.63M  1.42MB/s   in 10s    \n",
      "\n",
      "2017-01-24 12:20:22 (1.45 MB/s) - 'dataset.tar.gz.7' saved [15344424/15344424]\n",
      "\n",
      "x dataset/\n",
      "x dataset/._.DS_Store\n",
      "x dataset/.DS_Store\n",
      "x dataset/README\n",
      "x dataset/yes_big/\n",
      "x dataset/yes_complete/\n",
      "x dataset/yes_small/\n",
      "x dataset/yes_small/song_hash.txt\n",
      "x dataset/yes_small/tag_hash.txt\n",
      "x dataset/yes_small/tags.txt\n",
      "x dataset/yes_small/test.txt\n",
      "x dataset/yes_small/train.txt\n",
      "x dataset/yes_complete/song_hash.txt\n",
      "x dataset/yes_complete/tag_hash.txt\n",
      "x dataset/yes_complete/tags.txt\n",
      "x dataset/yes_complete/test.txt\n",
      "x dataset/yes_complete/train.txt\n",
      "x dataset/yes_big/song_hash.txt\n",
      "x dataset/yes_big/tag_hash.txt\n",
      "x dataset/yes_big/tags.txt\n",
      "x dataset/yes_big/test.txt\n",
      "x dataset/yes_big/train.txt\n"
     ]
    }
   ],
   "source": [
    "! wget http://www.cs.cornell.edu/~shuochen/lme/dataset.tar.gz\n",
    "! tar -xvf dataset.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17430147 17277121 17767569 17352501 17567841 17650\r\n",
      "19 456 22 82 120 854 597 20 160 76 415 493 81 29 1\r\n",
      "0 1 2 3 4 5 6 7 8 \r\n",
      "9 10 11 \r\n",
      "12 13 14 15 \r\n"
     ]
    }
   ],
   "source": [
    "! head -5 dataset/yes_small/train.txt | cut -c 1-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41480 playlists for a total of 175911 songs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>songs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[9, 10, 11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[12, 13, 14, 15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[16, 17, 18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[19]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         songs\n",
       "2  [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
       "3                  [9, 10, 11]\n",
       "4             [12, 13, 14, 15]\n",
       "5                 [16, 17, 18]\n",
       "6                         [19]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FIRST_FAULTY_PLAYLIST = 2\n",
    "playlists = pd.read_csv('dataset/yes_small/train.txt', header=None, names=['songs'])\\\n",
    "    .assign(songs=lambda df: df.songs.str.split(' ').apply(lambda ids: list(map(int, filter(None, ids)))))\\\n",
    "    .iloc[FIRST_FAULTY_PLAYLIST:,:]\n",
    "\n",
    "print('{} playlists for a total of {} songs'.format(playlists.shape[0], playlists.songs.apply(len).sum()))\n",
    "playlists.head()\n",
    "playlists.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175911, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playlist_id</th>\n",
       "      <th>position</th>\n",
       "      <th>song_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   playlist_id  position  song_id\n",
       "0            2         0        0\n",
       "1            2         1        1\n",
       "2            2         2        2\n",
       "3            2         3        3\n",
       "4            2         4        4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "playlist_songs = pd.DataFrame.from_records(\n",
    "    data=chain.from_iterable([(playlist_id, position, song_id) for position, song_id in enumerate(song_ids)] for playlist_id, (song_ids,) in playlists.iterrows()),\n",
    "    columns=['playlist_id', 'position', 'song_id'])\n",
    "\n",
    "print(playlist_songs.shape)\n",
    "playlist_songs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389728 playlists for a total of 1581007 songs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>songs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[3, 30, 38, 11, 39, 22, 40]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[12, 41, 42]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[43, 36]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[44]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         songs\n",
       "2  [3, 30, 38, 11, 39, 22, 40]\n",
       "3                 [12, 41, 42]\n",
       "4                     [43, 36]\n",
       "5                         [44]\n",
       "6                          [4]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FIRST_FAULTY_PLAYLIST = 2\n",
    "test_playlists = pd.read_csv('dataset/yes_small/test.txt', header=None, names=['songs'])\\\n",
    "    .assign(songs=lambda df: df.songs.str.split(' ').apply(lambda ids: list(map(int, filter(None, ids)))))\\\n",
    "    .iloc[FIRST_FAULTY_PLAYLIST:,:]\n",
    "\n",
    "print('{} playlists for a total of {} songs'.format(test_playlists.shape[0], test_playlists.songs.apply(len).sum()))\n",
    "test_playlists.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3168, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>artist_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>song_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Gucci Time (w\\/ Swizz Beatz)</td>\n",
       "      <td>Gucci Mane</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Aston Martin Music (w\\/ Drake &amp; Chrisette Mich...</td>\n",
       "      <td>Rick Ross</td>\n",
       "      <td>960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Get Back Up (w\\/ Chris Brown)</td>\n",
       "      <td>T.I.</td>\n",
       "      <td>1098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Hot Toddy (w\\/ Jay-Z &amp; Ester Dean)</td>\n",
       "      <td>Usher</td>\n",
       "      <td>1264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Whip My Hair</td>\n",
       "      <td>Willow</td>\n",
       "      <td>1304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         song_id                                              title  \\\n",
       "song_id                                                               \n",
       "0              0                       Gucci Time (w\\/ Swizz Beatz)   \n",
       "1              1  Aston Martin Music (w\\/ Drake & Chrisette Mich...   \n",
       "2              2                      Get Back Up (w\\/ Chris Brown)   \n",
       "3              3                 Hot Toddy (w\\/ Jay-Z & Ester Dean)   \n",
       "4              4                                       Whip My Hair   \n",
       "\n",
       "             artist  artist_id  \n",
       "song_id                         \n",
       "0        Gucci Mane        474  \n",
       "1         Rick Ross        960  \n",
       "2              T.I.       1098  \n",
       "3             Usher       1264  \n",
       "4            Willow       1304  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs = pd.read_csv('dataset/yes_small/song_hash.txt', sep='\\t', names=['song_id', 'title', 'artist'])\\\n",
    "    .set_index('song_id', drop=False)\\\n",
    "    .assign(artist_id=lambda df: df.artist.astype('category').cat.codes)\n",
    "\n",
    "print(songs.shape)\n",
    "songs.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>n_songs_played</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>.38 Special</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10 Years</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2Pac</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3 Doors Down</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   artist_id        artist  n_songs_played\n",
       "0          0             -              93\n",
       "1          1   .38 Special              47\n",
       "2          2      10 Years             152\n",
       "3          3          2Pac             146\n",
       "4          4  3 Doors Down             274"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists = songs.groupby('artist_id').first()[['artist']].reset_index()\n",
    "\n",
    "artist_songs_played = songs.artist.loc[playlist_songs.song_id].to_frame('artist')\\\n",
    "    .groupby('artist').size()\\\n",
    "    .sort_values(ascending=False).to_frame('n_songs_played')\n",
    "\n",
    "artists = pd.merge(artists, artist_songs_played.reset_index(), on='artist')\n",
    "artists.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick descriptive analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playlist_id</th>\n",
       "      <th>position</th>\n",
       "      <th>song_id</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>artist_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>All I Wants Is You (w\\/ J Cole)</td>\n",
       "      <td>Miguel</td>\n",
       "      <td>797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>Champagne Life</td>\n",
       "      <td>Ne-Yo</td>\n",
       "      <td>832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>Find Your Love</td>\n",
       "      <td>Drake</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>Your Love</td>\n",
       "      <td>Nicki Minaj</td>\n",
       "      <td>844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   playlist_id  position  song_id                            title  \\\n",
       "0            4         0       12  All I Wants Is You (w\\/ J Cole)   \n",
       "1            4         1       13                   Champagne Life   \n",
       "2            4         2       14                   Find Your Love   \n",
       "3            4         3       15                        Your Love   \n",
       "\n",
       "        artist  artist_id  \n",
       "0       Miguel        797  \n",
       "1        Ne-Yo        832  \n",
       "2        Drake        341  \n",
       "3  Nicki Minaj        844  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiEAAAFsCAYAAAAaOWmoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSJKkWvz/p1ASjBComQYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119e809e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(playlist_songs.groupby('playlist_id').size(), bins=np.logspace(0, 3, 30))\n",
    "plt.xscale('log')\n",
    "\n",
    "pd.merge(\n",
    "    playlist_songs.query('playlist_id == 4'),\n",
    "    songs,\n",
    "    on='song_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3168.000000\n",
       "mean     1583.500000\n",
       "std       914.667153\n",
       "min         0.000000\n",
       "25%       791.750000\n",
       "50%      1583.500000\n",
       "75%      2375.250000\n",
       "max      3167.000000\n",
       "Name: song_id, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs.song_id.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    175911.000000\n",
       "mean       1532.231151\n",
       "std        1016.879762\n",
       "min           0.000000\n",
       "25%         541.000000\n",
       "50%        1579.000000\n",
       "75%        2505.000000\n",
       "max        3167.000000\n",
       "Name: song_id, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist_songs.song_id.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip-gram generator\n",
    "\n",
    "Generating all pairs of co-played words (ie artists) from the same context (ie playlist), without taking into account the order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "song_id\n",
      "9      965\n",
      "10     394\n",
      "11    1264\n",
      "Name: artist_id, dtype: int16\n",
      "[(965, 394), (965, 1264), (394, 965), (394, 1264), (1264, 965), (1264, 394)]\n"
     ]
    }
   ],
   "source": [
    "from itertools import permutations, chain\n",
    "\n",
    "song_ids = playlist_songs.query('playlist_id == 3').song_id.values\n",
    "\n",
    "def artist_skip_grams(song_ids):\n",
    "    song_artist_ids = songs.artist_id.loc[song_ids].values\n",
    "    return [(a1, a2) for a1, a2 in permutations(song_artist_ids, 2) if a1 != a2]\n",
    "\n",
    "print(songs.artist_id.loc[song_ids])\n",
    "print(artist_skip_grams(song_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([474, 474, 474, 474, 474, 474, 474, 474, 960, 960], dtype=int32),\n",
       " array([ 960, 1098, 1264, 1304,  553, 1308, 1054,  707,  474, 1098], dtype=int32))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import islice, cycle\n",
    "\n",
    "class PlaylistToArtistPairs:\n",
    "\n",
    "    def __init__(self, batch_size, playlists=playlists):\n",
    "        all_artist_skip_grams = chain.from_iterable(map(artist_skip_grams, playlists.songs.values))\n",
    "        self.all_artist_skip_grams_iterable = cycle(all_artist_skip_grams)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __next__(self):\n",
    "        next_skip_grams = list(islice(self.all_artist_skip_grams_iterable, self.batch_size))\n",
    "        input_words, output_words = np.array(next_skip_grams, dtype=np.int32).T\n",
    "        return input_words, output_words\n",
    "\n",
    "    def next(self):\n",
    "        return self.__next__()\n",
    "    \n",
    "skipGramGenerator = PlaylistToArtistPairs(batch_size=10)\n",
    "\n",
    "next(skipGramGenerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%timeit sum(1 for _ in PlaylistToArtistPairs().all_artist_skip_grams_iterable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    2\n",
       "3    3\n",
       "4    4\n",
       "Name: song_id, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist_songs.song_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playlist_id</th>\n",
       "      <th>position</th>\n",
       "      <th>song_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   playlist_id  position  song_id\n",
       "0            2         0        0\n",
       "1            2         1        1\n",
       "2            2         2        2\n",
       "3            2         3        3\n",
       "4            2         4        4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist_songs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "song_id\n",
       "0     474\n",
       "1     960\n",
       "2    1098\n",
       "3    1264\n",
       "4    1304\n",
       "Name: artist_id, dtype: int16"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs.artist_id.loc[playlist_songs.song_id.head()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2vec as a simple shallow perceptron, on a toy dataset\n",
    "\n",
    " * at the heart, word2vec is a shallow 2 layers with a soft-max activation function that we feed with input and output pairs\n",
    " * From [word2vec Parameter Learning Explained](https://arxiv.org/abs/1411.2738):\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/2000/1*QXrebSekA-ClL154Ma89ZA.png\" width=\"600\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "Image(url= \"https://cdn-images-1.medium.com/max/2000/1*QXrebSekA-ClL154Ma89ZA.png\", width=600, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 2) example pairs with 2 unique ids\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 2],\n",
       "       [1, 2],\n",
       "       [2, 3],\n",
       "       [3, 2]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_output_pairs = np.array([\n",
    "    [0, 1], [1, 0], [0, 1], [1, 2], [1, 2], [2, 3], [3, 2]])\n",
    "\n",
    "vocabulary_size = np.unique(input_output_pairs).shape[0]\n",
    "hidden_layer_size = embedding_size = 2\n",
    "\n",
    "print('{} example pairs with {} unique ids'.format(input_output_pairs.shape, hidden_layer_size))\n",
    "input_output_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st exercise: Keras implementation\n",
    "\n",
    " * Define a `keras.models.Sequential` using the `Embedding, Reshape, Dense, Activation` from `keras.layers` (TIP order is correct ;)) \n",
    " * TIP: I had to use `Reshape` in between `Embedding` to drop the superfluous dimension output from `Embedding(..., input_length=1)`\n",
    " * test right away the model by asking output probabilities given a single input id using `model.predict(x=[[1]])`\n",
    " * Execute `model.compile` and `model.fit` to run on epoch of backpropagation (TIP: pass `input_output_pairs[:, 0]` and `input_output_pairs[:, 1]` as inputs to `fit`)\n",
    " * Look at `input_layer.weights[0].eval()` to check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Embedding, Reshape, Dense, Activation\n",
    "from keras.models import Sequential\n",
    "from keras import backend as K\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "K.set_session(sess)\n",
    "\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_layer = Embedding(input_dim=vocabulary_size, output_dim=embedding_size, input_length=1, init='uniform')\n",
    "\n",
    "output_layer = Dense(output_dim=vocabulary_size, bias=False)\n",
    "\n",
    "model = Sequential([\n",
    "    input_layer,\n",
    "    Reshape((embedding_size,)), # getting rid of the superfluous dimension of input_length=1\n",
    "    output_layer,\n",
    "    Activation('softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.24775435,  0.25582856,  0.25074571,  0.24567135]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x=np.array([[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/7 [==============================] - 0s - loss: 1.3754\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s - loss: 1.3747\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 0s - loss: 1.3739\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 0s - loss: 1.3731\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s - loss: 1.3724\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 0s - loss: 1.3716\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 0s - loss: 1.3708\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s - loss: 1.3701\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 0s - loss: 1.3693\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s - loss: 1.3686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11d3adf60>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd')\n",
    "model.fit(x=input_output_pairs[:, 0], y=input_output_pairs[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04523154, -0.05406943],\n",
       "       [-0.01869763, -0.02119141],\n",
       "       [-0.0391637 ,  0.04367046],\n",
       "       [ 0.00987293,  0.03031986]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looks ok, 0 and 3 are the most different, while 1 and 2 in-between\n",
    "input_layer.weights[0].eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras artist2vec \n",
    "\n",
    " * almost copy and paste of the toy example!\n",
    " * use `model.fit_generator` with `PlaylistToArtistPairs`\n",
    " * TIP model.fit_generator(generator=PlaylistToArtistPairs(batch_size=BATCH_SIZE),\n",
    "                    samples_per_epoch=10*BATCH_SIZE, nb_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "N_ARTISTS = songs.artist_id.max() + 1\n",
    "EMBEDDING_DIM = 20\n",
    "\n",
    "input_layer = Embedding(input_dim=N_ARTISTS, output_dim=EMBEDDING_DIM, input_length=1, init='uniform')\n",
    "\n",
    "output_layer = Dense(output_dim=N_ARTISTS, bias=False)\n",
    "\n",
    "model = Sequential([\n",
    "    input_layer,\n",
    "    Reshape((EMBEDDING_DIM,)), # getting rid of the superfluous dimension of input_length=1\n",
    "    output_layer,\n",
    "    Activation('softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100000/100000 [==============================] - 6s - loss: 7.1770     \n",
      "Epoch 2/10\n",
      "100000/100000 [==============================] - 6s - loss: 7.0867     \n",
      "Epoch 3/10\n",
      "100000/100000 [==============================] - 6s - loss: 6.7710     \n",
      "Epoch 4/10\n",
      "100000/100000 [==============================] - 6s - loss: 6.3392     \n",
      "Epoch 5/10\n",
      "100000/100000 [==============================] - 5s - loss: 6.3288     \n",
      "Epoch 6/10\n",
      "100000/100000 [==============================] - 6s - loss: 5.5508     \n",
      "Epoch 7/10\n",
      "100000/100000 [==============================] - 6s - loss: 5.4935     \n",
      "Epoch 8/10\n",
      "100000/100000 [==============================] - 6s - loss: 5.4221     \n",
      "Epoch 9/10\n",
      "100000/100000 [==============================] - 6s - loss: 5.0866     \n",
      "Epoch 10/10\n",
      "100000/100000 [==============================] - 6s - loss: 4.9812     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11fdc6710>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 10000\n",
    "\n",
    "model.fit_generator(generator=PlaylistToArtistPairs(batch_size=BATCH_SIZE),\n",
    "                    samples_per_epoch=10*BATCH_SIZE, nb_epoch=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd exercise : Tensorflow implementation\n",
    "\n",
    "### Model components and forward part:\n",
    "\n",
    " * define `tf.placeholder` for `input_ids`\n",
    " * define two `tf.Variable` for the model weights `W_input` and `W_output` using the size `vocabulary_size x embedding_size`\n",
    " * initialise these variables by doing `sess.run([W_input.initializer, W_output.initializer])`\n",
    " * print `W_input.eval()`\n",
    " * use `tf.nn.embedding_lookup`, `tf.matmul` and `tf.nn.softmax` assemble the whole to return tensors `output_word_scores` and `output_probabilities`\n",
    " * Test by printing `output_probabilities.eval(...)` or `sess.run(output_probabilities, ...)` by feeding `feed_dict = {input_ids: [input_word]}`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_input:\n",
      " [[ 0.08652782 -0.34646392]\n",
      " [-0.64871407  0.78041172]\n",
      " [ 0.46208     0.63580108]\n",
      " [ 0.26514316 -0.2523613 ]]\n",
      "W_input[input_word]: [[-0.64871407  0.78041172]]\n",
      "output_word_scores: [[ 0.75768137  0.57094318 -0.5361951  -0.12813765]]\n",
      "output P[W_O|W_I = input_word]: [[ 0.3974179   0.32972211  0.10897429  0.16388571]]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = None\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "input_ids = tf.placeholder(tf.int32, shape=[BATCH_SIZE])\n",
    "\n",
    "W_input = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n",
    "W_output = tf.Variable(tf.random_uniform([embedding_size, vocabulary_size], -1.0, 1.0))\n",
    "sess.run([W_input.initializer, W_output.initializer])\n",
    "\n",
    "W_input.eval()\n",
    "\n",
    "input_vector = tf.nn.embedding_lookup(W_input, input_ids)\n",
    "output_word_scores = tf.matmul(input_vector, W_output)\n",
    "output_probabilities = tf.nn.softmax(output_word_scores)\n",
    "\n",
    "input_word = 1\n",
    "feed_dict = {input_ids: [input_word]}\n",
    "\n",
    "print('W_input:\\n', W_input.eval())\n",
    "print('W_input[input_word]:', input_vector.eval(feed_dict))\n",
    "print('output_word_scores:', output_word_scores.eval(feed_dict))\n",
    "print('output P[W_O|W_I = input_word]:',output_probabilities.eval(feed_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training through backpropagation:\n",
    "\n",
    " * define `tf.placeholder` for `output_ids` (same size as `input_ids`)\n",
    " * define an average loss tensor from `output_word_scores` and `output_ids` using `tf.reduce_mean` and `tf.nn.sparse_softmax_cross_entropy_with_logits`\n",
    " * test by printing `loss.eval(feed_dict)` by feeding `feed_dict = {input_ids: input_output_pairs[:, 0], output_ids: input_output_pairs[:, 1]}`\n",
    " * define a `train_step = tf.train.GradientDescentOptimizer(learning_rate=1).minimize(loss)`, run it once using `sess.run(train_step, feed_dict)` and print `W_input.eval()` and `loss` to see the changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.nn.sparse_softmax_cross_entropy_with_logits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.59776\n",
      "loss: 1.43065\n",
      "W_input:\n",
      " [[ 0.11283824 -0.15312684]\n",
      " [-0.48019004  0.63776666]\n",
      " [ 0.47041962  0.59412318]\n",
      " [ 0.35223305 -0.28939322]]\n",
      "loss: 1.36545\n",
      "W_input:\n",
      " [[ 0.16241732 -0.03266931]\n",
      " [-0.39228451  0.57355899]\n",
      " [ 0.48847365  0.56620526]\n",
      " [ 0.4162063  -0.30685082]]\n",
      "loss: 1.3317\n",
      "W_input:\n",
      " [[ 0.21983972  0.04788139]\n",
      " [-0.3510949   0.54481167]\n",
      " [ 0.5145883   0.54538041]\n",
      " [ 0.46453491 -0.31270307]]\n"
     ]
    }
   ],
   "source": [
    "output_ids = tf.placeholder(tf.int32, shape=[BATCH_SIZE])\n",
    "feed_dict = {input_ids: input_output_pairs[:, 0], output_ids: input_output_pairs[:, 1]}\n",
    "\n",
    "loss = tf.reduce_mean(\n",
    "    tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits=output_word_scores,\n",
    "        labels=output_ids))\n",
    "\n",
    "print('loss:', loss.eval(feed_dict))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate=1).minimize(loss)\n",
    "         \n",
    "sess.run(train_step, feed_dict)\n",
    "print('loss:', loss.eval(feed_dict))\n",
    "print('W_input:\\n', W_input.eval())\n",
    "\n",
    "sess.run(train_step, feed_dict)\n",
    "print('loss:', loss.eval(feed_dict))\n",
    "print('W_input:\\n', W_input.eval())\n",
    "\n",
    "sess.run(train_step, feed_dict)\n",
    "print('loss:', loss.eval(feed_dict))\n",
    "print('W_input:\\n', W_input.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow artist2vec\n",
    "\n",
    " * For a nice introduction https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/ with lots of lovely diagrams.\n",
    "\n",
    " * https://www.tensorflow.org/tutorials/word2vec/ is a good self-contained ressource with explanations as well as code hints.\n",
    "\n",
    "However, their implementation uses some high-level optimised function (namely the `tf.nn.nce_loss`) that makes the code less didactic without having any impact for the size of our dataset. \n",
    "\n",
    "Therefore it's a better exercise to:\n",
    "\n",
    " * Define `input_embeddings = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))` and the symmetrical `hidden_embeddings` (instead of `nce_weights`) as in the schema below\n",
    " * Drop the `nce_biases` altogether\n",
    " * Multiply the `embed` tensor with the `hidden_embeddings` to calculate a `(N_SAMPLES x N_OUTPUT_SONGS)` `logits` tensor (hint: use `tf.matmul` and `tf.transpose`)\n",
    " * Feed `logits` and `train_labels` into `tf.nn.sparse_softmax_cross_entropy_with_logits` as we did for the [iris classification](https://github.com/pilipolio/schibsted-study/blob/master/notebooks/201611_multiclass_classification.ipynb)\n",
    " * (Or alternatively compute manually the softmax loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N_ARTISTS = songs.artist_id.max() + 1\n",
    "\n",
    "class Artist2Vec:\n",
    "    def __init__(self, n_entities, dimensionality=50, batch_size=None):\n",
    "        \n",
    "        with tf.name_scope('input_embeddings'):\n",
    "            input_embeddings = tf.Variable(tf.random_normal([n_entities, dimensionality], \n",
    "                                                           stddev=0.01, mean=0), name='input')\n",
    "            tf.histogram_summary('input_embeddings', input_embeddings)\n",
    "\n",
    "        with tf.name_scope('output_embeddings'):\n",
    "            output_embeddings = tf.Variable(tf.random_normal([n_entities, dimensionality], stddev=0.01, mean=0), name='output')\n",
    "            tf.histogram_summary('output_embeddings', output_embeddings)\n",
    "\n",
    "        with tf.name_scope('output_bias'):\n",
    "            output_biases = tf.Variable(tf.random_normal([n_entities], stddev=0.01, mean=0), name='output_bias')\n",
    "            tf.histogram_summary('output_biases', output_biases)\n",
    "        \n",
    "        self.n_entities = n_entities\n",
    "        self.output_biases = output_biases\n",
    "        self.input_embeddings = input_embeddings\n",
    "        self.output_embeddings = output_embeddings\n",
    "    \n",
    "        self.input_artist_ids = tf.placeholder(\n",
    "            tf.int32, shape=[batch_size], name='input_artist_ids')\n",
    "        self.output_artist_ids = tf.placeholder(\n",
    "            tf.int32, shape=[batch_size], name='output_artist_ids')\n",
    "\n",
    "    def input_to_all_output_logits(self):\n",
    "        \"\"\"\n",
    "        The architecture is made of:\n",
    "         * input nodes for the user_id, and associated weights or embeddings V_u\n",
    "         * internal weights W_i and biases b_i for each items\n",
    "        \"\"\"\n",
    "        return self.output_biases + tf.matmul(\n",
    "                tf.nn.embedding_lookup(self.input_embeddings, self.input_artist_ids),\n",
    "                tf.transpose(self.output_embeddings), name='input_to_all_output_logits')\n",
    "        \n",
    "    def exact_loss(self):\n",
    "        with tf.name_scope('loss'):\n",
    "            cross_entropy_sum = tf.reduce_mean(\n",
    "                tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                    logits=self.input_to_all_output_logits(),\n",
    "                    labels=self.output_artist_ids))\n",
    "        return cross_entropy_sum\n",
    "    \n",
    "    def sampled_loss(self):\n",
    "        with tf.name_scope('loss'):\n",
    "            sample_losses = tf.nn.sampled_softmax_loss(\n",
    "                biases=self.output_biases,\n",
    "                inputs=tf.nn.embedding_lookup(self.input_embeddings, self.input_artist_ids),\n",
    "                labels=tf.reshape(self.output_artist_ids, (-1, 1)),\n",
    "                weights=self.output_embeddings,\n",
    "                num_classes=self.n_entities,\n",
    "                num_sampled=10, num_true=1)\n",
    "            return tf.reduce_mean(sample_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_embeddings_metadata(model, summary_writer):\n",
    "    \"\"\" From https://www.tensorflow.org/versions/r0.12/how_tos/embedding_viz/index.html#tensorboard-embedding-visualization\n",
    "    \"\"\"\n",
    "    embeddings_metadata_path = os.path.join(LOG_DIR, 'artist_embeddings.tsv')\n",
    "    artists.to_csv(embeddings_metadata_path, sep='\\t')\n",
    "\n",
    "    config = projector.ProjectorConfig()\n",
    "    for embeddings_variable in [model.output_embeddings, model.input_embeddings]:\n",
    "        embedding = config.embeddings.add()\n",
    "        embedding.tensor_name = embeddings_variable.name\n",
    "        embedding.metadata_path = embeddings_metadata_path\n",
    "    \n",
    "    projector.visualize_embeddings(summary_writer, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, batch_loss = 7.19, test_loss = 7.18\n",
      "step 10, batch_loss = 6.84, test_loss = 6.11\n",
      "step 20, batch_loss = 5.34, test_loss = 4.23\n",
      "step 30, batch_loss = 4.83, test_loss = 4.08\n",
      "step 40, batch_loss = 4.84, test_loss = 4.09\n",
      "step 50, batch_loss = 5.15, test_loss = 3.93\n",
      "step 60, batch_loss = 4.59, test_loss = 4.46\n",
      "step 70, batch_loss = 4.60, test_loss = 4.71\n",
      "step 80, batch_loss = 4.55, test_loss = 4.57\n",
      "step 90, batch_loss = 4.55, test_loss = 4.19\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "import os\n",
    "\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "\n",
    "LEARNING_RATE = 0.005\n",
    "BATCH_SIZE = 10000\n",
    "N_ITER = 100\n",
    "LOG_DIR = '/tmp/tf_logs'\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    model = Artist2Vec(n_entities=N_ARTISTS, dimensionality=20)\n",
    "    loss = model.exact_loss()    #.sampled_loss()\n",
    "    \n",
    "    tf.scalar_summary('batch_loss', loss)\n",
    "    summary = tf.merge_all_summaries()\n",
    "    test_summary = tf.scalar_summary('test_loss', loss)\n",
    "    train_step = tf.train.AdamOptimizer(LEARNING_RATE).minimize(loss)\n",
    "    \n",
    "    test_generator = PlaylistToArtistPairs(playlists=test_playlists, batch_size=BATCH_SIZE)\n",
    "    skip_grams_generator = PlaylistToArtistPairs(batch_size=BATCH_SIZE * 10)\n",
    "    \n",
    "    def perform_step(step, summary_writer):\n",
    "        batch_input_ids, batch_output_ids = next(skip_grams_generator)\n",
    "        _, loss_value, summary_value = sess.run(\n",
    "            fetches=[train_step, loss, summary], \n",
    "            feed_dict={\n",
    "                model.input_artist_ids: batch_input_ids,\n",
    "                model.output_artist_ids: batch_output_ids\n",
    "            })\n",
    "        summary_writer.add_summary(summary_value, global_step=step)\n",
    "        \n",
    "        if step% 10 == 0:\n",
    "            test_input_ids, test_output_ids = next(test_generator)\n",
    "            test_loss_value, test_summary_value = sess.run(\n",
    "            fetches=[loss, test_summary], \n",
    "            feed_dict={\n",
    "                model.input_artist_ids: test_input_ids,\n",
    "                model.output_artist_ids: test_output_ids\n",
    "            })\n",
    "\n",
    "            print('step {step}, batch_loss = {loss_value:.2f}, test_loss = {test_loss_value:.2f}'.format(**locals()))\n",
    "            summary_writer.add_summary(test_summary_value, global_step=step)\n",
    "        summary_writer.flush()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        summary_writer = tf.train.SummaryWriter(\n",
    "            os.path.join(LOG_DIR,'{:%Y%m%d%H%M%S}'.format(dt.datetime.now())),\n",
    "            sess.graph)\n",
    "\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for step in range(N_ITER):\n",
    "            perform_step(step, summary_writer)\n",
    "        \n",
    "        input_embeddings = model.input_embeddings.eval()\n",
    "        output_embeddings = model.output_embeddings.eval()\n",
    "        \n",
    "        saver = tf.train.Saver()\n",
    "        saver.save(sess, os.path.join(LOG_DIR, \"model.ckpt\"), step)\n",
    "        save_embeddings_metadata(model, summary_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(input_embeddings).to_csv(os.path.join(LOG_DIR, \"input_embeddings.tsv\"), sep='\\t', index=None, header=None)\n",
    "pd.DataFrame(output_embeddings).to_csv(os.path.join(LOG_DIR, \"output_embeddings.tsv\"), sep='\\t', index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML, display\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "from scipy import spatial\n",
    "\n",
    "def embeddings_to_distances(embeddings):\n",
    "    item_item_distances = pd.DataFrame(\n",
    "        index=embeddings.index,\n",
    "        columns=embeddings.index,\n",
    "        data=spatial.distance.squareform(spatial.distance.pdist(embeddings.values, metric='cosine'))\n",
    "    )\n",
    "    return item_item_distances\n",
    "\n",
    "def topn_most_similar(item_id, topn, item_item_distances):\n",
    "    candidate_distances = item_item_distances.loc[item_id]\n",
    "    return candidate_distances.sort_values().iloc[1:(topn+1)].to_frame('distance')\n",
    "\n",
    "def display_items(from_id, to_items_df, items_metadata):\n",
    "    display(HTML(items_metadata.loc[[from_id]].to_html()))\n",
    "    display(HTML(to_items_df.join(items_metadata).to_html()))\n",
    "    \n",
    "def display_topn_most_similar(item_id, distances, topn, items_metadata):\n",
    "    most_similar = topn_most_similar(item_id, topn, distances)\n",
    "    display_items(item_id, most_similar, items_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distances = embeddings_to_distances(pd.DataFrame(data=input_embeddings))\n",
    "distances = embeddings_to_distances(pd.DataFrame(data=output_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>n_songs_played</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>Abba</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>n_songs_played</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0.004822</td>\n",
       "      <td>890</td>\n",
       "      <td>Paula Abdul</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>0.007908</td>\n",
       "      <td>1005</td>\n",
       "      <td>Seal</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>0.008009</td>\n",
       "      <td>1117</td>\n",
       "      <td>The 4 Seasons</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.008588</td>\n",
       "      <td>500</td>\n",
       "      <td>Howard Jones</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0.008753</td>\n",
       "      <td>246</td>\n",
       "      <td>Club Nouveau</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ABBA = 19\n",
    "display_topn_most_similar(item_id=ABBA, distances=distances, topn=5, items_metadata=artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>n_songs_played</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>1300</td>\n",
       "      <td>Whitney Houston</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>n_songs_played</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>0.003844</td>\n",
       "      <td>573</td>\n",
       "      <td>Joe</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0.004320</td>\n",
       "      <td>166</td>\n",
       "      <td>Brian Bromberg</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>0.004613</td>\n",
       "      <td>878</td>\n",
       "      <td>Patrice Rushen</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>0.004632</td>\n",
       "      <td>1123</td>\n",
       "      <td>The Art Of Noise</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>0.004802</td>\n",
       "      <td>1282</td>\n",
       "      <td>Walter Beasley</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "WITNEY = 1300\n",
    "display_topn_most_similar(item_id=WITNEY, distances=distances, topn=5, items_metadata=artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>n_songs_played</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2Pac</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>n_songs_played</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.008655</td>\n",
       "      <td>80</td>\n",
       "      <td>Baby Bash</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>0.012132</td>\n",
       "      <td>455</td>\n",
       "      <td>Gorilla Zoe</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>0.019753</td>\n",
       "      <td>1180</td>\n",
       "      <td>The Notorious B.I.G.</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>0.025377</td>\n",
       "      <td>751</td>\n",
       "      <td>Mann</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>0.031149</td>\n",
       "      <td>1096</td>\n",
       "      <td>T-Pain</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TWOPAC = 3\n",
    "display_topn_most_similar(item_id=TWOPAC, distances=distances, topn=5, items_metadata=artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>n_songs_played</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>1129</td>\n",
       "      <td>The Beatles</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>n_songs_played</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>0.002155</td>\n",
       "      <td>1093</td>\n",
       "      <td>Supertramp</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.002457</td>\n",
       "      <td>82</td>\n",
       "      <td>Bachman-Turner Overdrive</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>0.003299</td>\n",
       "      <td>1070</td>\n",
       "      <td>Steppenwolf</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>0.004395</td>\n",
       "      <td>1153</td>\n",
       "      <td>The Electric Light Orchestra</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>0.007777</td>\n",
       "      <td>897</td>\n",
       "      <td>Peter Frampton</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>0.010482</td>\n",
       "      <td>1148</td>\n",
       "      <td>The Doobie Brothers</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>0.012040</td>\n",
       "      <td>750</td>\n",
       "      <td>Manfred Mann's Earth Band</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>0.012194</td>\n",
       "      <td>218</td>\n",
       "      <td>Cheap Trick</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>0.015894</td>\n",
       "      <td>582</td>\n",
       "      <td>John Cougar Mellencamp</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>0.018002</td>\n",
       "      <td>1152</td>\n",
       "      <td>The Edgar Winter Group</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BEATLES = 1129\n",
    "#output_distances = embeddings_to_distances(pd.DataFrame(data=output_embeddings))\n",
    "display_topn_most_similar(item_id=BEATLES, distances=distances, topn=10, items_metadata=artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>n_songs_played</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>1190</td>\n",
       "      <td>The Rolling Stones</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>n_songs_played</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>0.021333</td>\n",
       "      <td>928</td>\n",
       "      <td>Queen</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>0.026452</td>\n",
       "      <td>743</td>\n",
       "      <td>Lynyrd Skynyrd</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>0.026862</td>\n",
       "      <td>1195</td>\n",
       "      <td>The Steve Miller Band</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>0.028502</td>\n",
       "      <td>1204</td>\n",
       "      <td>The Who</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1320</th>\n",
       "      <td>0.031876</td>\n",
       "      <td>1320</td>\n",
       "      <td>ZZ Top</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.032048</td>\n",
       "      <td>154</td>\n",
       "      <td>Boston</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>0.033251</td>\n",
       "      <td>485</td>\n",
       "      <td>Heart</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>0.035406</td>\n",
       "      <td>267</td>\n",
       "      <td>Creedence Clearwater Revival</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>0.041879</td>\n",
       "      <td>1233</td>\n",
       "      <td>Tom Petty &amp; The Heartbreakers</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.043409</td>\n",
       "      <td>84</td>\n",
       "      <td>Bad Company</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ROLLING = 1190\n",
    "display_topn_most_similar(item_id=ROLLING, distances=distances, topn=10, items_metadata=artists)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
