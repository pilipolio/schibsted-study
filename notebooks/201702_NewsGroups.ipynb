{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20 newsgroups dataset shows NMF parts-based decomposition\n",
    "http://scikit-learn.org/stable/datasets/twenty_newsgroups.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism',\n",
      " 'sci.space',\n",
      " 'talk.politics.guns',\n",
      " 'talk.politics.misc',\n",
      " 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = ['alt.atheism', 'talk.religion.misc', 'talk.politics.guns', 'sci.space', 'talk.politics.misc']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', \n",
    "                                      remove=('headers', 'footers', 'quotes'),\n",
    "                                      categories=categories)\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(list(newsgroups_train.target_names)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2461,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.filenames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2461,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 3, 1, 4, 0, 2, 2, 1, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.target[:10] #  The target attribute is the integer index of the category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare vectors from train set using CountVectorizer\n",
    "See http://scikit-learn.org/stable/modules/feature_extraction.html#common-vectorizer-usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.9, max_features=None, min_df=0.01,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words='english', max_df=0.9, min_df=0.01)\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2461x1465 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 93788 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze = vectorizer.build_analyzer()\n",
    "analyze(\"This is a text document to analyze.\") == (['text', 'document', 'analyze'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1465"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['father',\n",
       " 'fault',\n",
       " 'fbi',\n",
       " 'fear',\n",
       " 'federal',\n",
       " 'feds',\n",
       " 'feel',\n",
       " 'feet',\n",
       " 'field',\n",
       " 'fight']"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[500:510]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_.get('attitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['completely', 'new'], \n",
       "      dtype='<U15')"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = np.array(vectorizer.get_feature_names())\n",
    "sparse_array_of_features = vectorizer.transform(['Something completely new.'])\n",
    "#feature_names[sparse_array_of_features.toarray().nonzero()[1]]\n",
    "feature_names[sparse_array_of_features.tocoo().col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.10971149939049"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.nnz / float(vectors.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract components using NMF from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "model = NMF(n_components=10)\n",
    "model.fit(vectors)\n",
    "vectors_transformed = model.transform(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1465)\n"
     ]
    }
   ],
   "source": [
    "print(model.components_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['united' 'firearms' 'states' 'congress' 'mr' 'file' 'gun' 'control']\n",
      "['did' 'said' 'think' 'mr' 'know' 'going' 'don' 'president']\n",
      "['earth' 'shuttle' 'information' 'available' 'edu' 'nasa' 'space' 'lunar']\n",
      "['believe' 'religious' 'god' 'atheism' 'true' 'does' 'people' 'atheists']\n",
      "['program' 'american' 'government' 'think' 'official' 'russian' 'president'\n",
      " 'administration']\n",
      "['plan' 'nuclear' 'time' 'british' 'war' 'south' 'military' 'new']\n",
      "['course' 'david' 'said' 'king' 'lord' 'people' 'jesus' 'matthew']\n",
      "['secretary' 'school' 'want' 'summer' 'young' 'people' 'jobs' 'work']\n",
      "['market' 'services' 'year' 'satellites' 'commercial' 'satellite' 'launch'\n",
      " 'space']\n",
      "['person' 'license' 'shall' 'dangerous' 'military' 'firearm' 'section'\n",
      " 'weapon']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vectorizer.get_feature_names())\n",
    "\n",
    "for component in model.components_:\n",
    "    indices = np.argpartition(component, -10)[-8:] # take 10 words with biggest value    \n",
    "    print(feature_names[indices])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00170674,  0.03223595,  0.        ,  0.07593286,  0.        ,\n",
       "         0.00189783,  0.0280003 ,  0.12034418,  0.        ,  0.07486981]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transform(vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare vectors from train set using CountVectorizer with bi-grams of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigram_vectorizer = CountVectorizer(ngram_range=(1,5), \n",
    "                                    stop_words='english', max_df=0.95, min_df=0.001)\n",
    "analyze = bigram_vectorizer.build_analyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze('Bi-grams are cool!') == (['bi grams', 'grams cool', 'bi grams cool'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2461x5503 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 25106 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_vectors = bigram_vectorizer.fit_transform(newsgroups_train.data)\n",
    "bigram_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5503"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bigram_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['basis values',\n",
       " 'batf fbi',\n",
       " 'batf needed',\n",
       " 'batf proper',\n",
       " 'bauer arndt',\n",
       " 'bay area',\n",
       " 'bbs 513',\n",
       " 'bbs accessed',\n",
       " 'bd did',\n",
       " 'bear arms']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_vectorizer.get_feature_names()[500:510]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.2015440877692"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_vectors.nnz / float(bigram_vectors.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "bigram_model = NMF(n_components=10)\n",
    "bigram_model.fit(bigram_vectors)\n",
    "bigram_vectors_transformed = bigram_model.transform(bigram_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5503)\n"
     ]
    }
   ],
   "source": [
    "print(bigram_model.components_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stimulus package' 'senator dole' 'working groups' 'white house'\n",
      " 'task force' 'going continue' 'stephanopoulos think' 'mr stephanopoulos'\n",
      " 'don know' 'stephanopoulos don']\n",
      "['journal medicine' 'england journal' 'new england' 'waiting period'\n",
      " 'title 18' '18 united' 'states code' 'gun control' 'united states'\n",
      " 'second amendment']\n",
      "['mr teel' '1993 15' 'don like' 'uchicago edu' 'ted frank' 'apr 1993'\n",
      " 'dendrite cs' 'ajteel dendrite' 'colorado edu' 'cs colorado']\n",
      "['thu apr' 'apr 14' 'arc nasa' 'pub space' 'nasa gov' 'directory pub'\n",
      " 'available anonymous' 'anonymous ftp' 'sci space' 'space shuttle']\n",
      "['work force' 'high school' 'business community' 'young people'\n",
      " 'summer jobs' 'jobs program' 'president think' 'private sector'\n",
      " 'mr president' 'secretary reich']\n",
      "['don think' 'continue work' 'task force' 'russian aid' 'working groups'\n",
      " 'dee dee' 'stimulus package' 'don know' 'jobs package' 'health care']\n",
      "['think important' 'soviet union' 'president clinton' 'southern hemisphere'\n",
      " 'private sector' 'united states' 'think fair' 'new zealand' 'long term'\n",
      " 'president yeltsin']\n",
      "['space launch' 'mcdonnell douglas' 'national space' 'launch services'\n",
      " 'launch site' 'space technology' 'remote sensing' 'commercial launch'\n",
      " 'launch vehicle' 'commercial space']\n",
      "['atheism faq' 'religious beliefs' 'strong atheism' 'god exists'\n",
      " 'don believe' 'believe god' 'does exist' 'god does' 'alt atheism'\n",
      " 'existence god']\n",
      "['jesus lucifer' 'ra bible' 'says bible' 'mcconkie views' 'mormon belief'\n",
      " 'bible teaches' 'jesus christ' 'god ra' 'children god' 'true god']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(bigram_vectorizer.get_feature_names())\n",
    "\n",
    "for component in bigram_model.components_:\n",
    "    indices = np.argpartition(component, -10)[-10:] # take 10 words with biggest value    \n",
    "    print(feature_names[indices])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
